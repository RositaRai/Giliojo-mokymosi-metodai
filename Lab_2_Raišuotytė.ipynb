{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Rosita Raišuotytė 2016026 [\"Deer\", \"Car\", \"Helicopter\"]"
      ],
      "metadata": {
        "id": "wpXhtetH4w1V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SwG5Ug-OkA1_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from pandas.core.common import flatten\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "from typing import Tuple, Dict, List\n",
        "\n",
        "import glob\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgrUeICX7NXI"
      },
      "source": [
        "# Nuotraukų parsisiuntimas naudojantis openimages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KNcvBAl7MdB",
        "outputId": "833cfae2-97d3-445b-f5cb-8f48bed650af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openimages\n",
            "  Downloading openimages-0.0.1-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from openimages) (4.9.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openimages) (4.65.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from openimages) (1.4.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from openimages) (2.27.1)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.96-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.5/135.5 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cvdata\n",
            "  Downloading cvdata-0.0.3-py3-none-any.whl (37 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.30.0,>=1.29.96\n",
            "  Downloading botocore-1.29.96-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m112.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from cvdata->openimages) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from cvdata->openimages) (1.22.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.9/dist-packages (from cvdata->openimages) (4.7.0.72)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->openimages) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->openimages) (2.8.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->openimages) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->openimages) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->openimages) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->openimages) (2.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->openimages) (1.16.0)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, cvdata, openimages\n",
            "Successfully installed boto3-1.26.96 botocore-1.29.96 cvdata-0.0.3 jmespath-1.0.1 openimages-0.0.1 s3transfer-0.6.0\n"
          ]
        }
      ],
      "source": [
        "pip install openimages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "M6FTk9Mk7eer"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openimages.download import download_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rM2CLbCT7eqs"
      },
      "outputs": [],
      "source": [
        "data_dir = \"OpenImages\"\n",
        "\n",
        "if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir)\n",
        "\n",
        "number_for_samples = 2000\n",
        "classes = ['Deer', 'Car', 'Helicopter']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm9PoBWw7n4c",
        "outputId": "736ec9ac-9b5c-4c6b-e8ea-b9d4c94a2f5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading is starting...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 711/711 [00:44<00:00, 16.09it/s]\n",
            "100%|██████████| 2000/2000 [01:56<00:00, 17.19it/s]\n",
            "100%|██████████| 1067/1067 [01:03<00:00, 16.77it/s]\n",
            "100%|██████████| 49/49 [00:04<00:00, 10.45it/s]\n",
            "100%|██████████| 177/177 [00:11<00:00, 15.24it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'deer': {'images_dir': 'OpenImages/deer/images'},\n",
              " 'car': {'images_dir': 'OpenImages/car/images'},\n",
              " 'helicopter': {'images_dir': 'OpenImages/helicopter/images'}}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "print(\"Downloading is starting...\")\n",
        "download_dataset(data_dir, classes, limit=number_for_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ExSy_yp98aWd"
      },
      "outputs": [],
      "source": [
        "def get_photo_paths(data_path):\n",
        "  image_paths = []\n",
        "  image_paths_car = []\n",
        "  image_paths_deer = []\n",
        "  image_paths_helicopter = []\n",
        "\n",
        "  for data_path in glob.glob(data_path + '/*'):\n",
        "    paths = glob.glob(data_path + '/images/*')\n",
        "    print(data_path, ' ', len(paths))\n",
        "\n",
        "    for photo_path in paths:\n",
        "      if re.search(\".*car\", photo_path):\n",
        "        image_paths_car.append(photo_path)\n",
        "      if re.search(\".*deer\", photo_path):\n",
        "        image_paths_deer.append(photo_path) \n",
        "      if re.search(\".*helicopter\", photo_path):\n",
        "        image_paths_helicopter.append(photo_path)  \n",
        "    \n",
        "  return list(flatten(image_paths_car)), list(flatten(image_paths_deer)), list(flatten(image_paths_helicopter)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rWiTn7J8p-z",
        "outputId": "2308dc30-693a-4d41-91c7-66d34cb5e1d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenImages/helicopter   1067\n",
            "OpenImages/car   2000\n",
            "OpenImages/deer   937\n",
            "3202\n",
            "401\n"
          ]
        }
      ],
      "source": [
        "image_paths_car, image_paths_deer, image_paths_helicopter = get_photo_paths(data_dir)\n",
        "image_classes = ['deer', 'car', 'helicopter']\n",
        "\n",
        "split_1 = int(0.8 * len(image_paths_car))\n",
        "split_2 = int(0.9 * len(image_paths_car))\n",
        "train_filenames_car = image_paths_car[:split_1]\n",
        "test_filenames_car = image_paths_car[split_2:]\n",
        "\n",
        "split_1 = int(0.8 * len(image_paths_deer))\n",
        "split_2 = int(0.9 * len(image_paths_deer))\n",
        "train_filenames_deer = image_paths_deer[:split_1]\n",
        "test_filenames_deer = image_paths_deer[split_2:]\n",
        "\n",
        "split_1 = int(0.8 * len(image_paths_helicopter))\n",
        "split_2 = int(0.9 * len(image_paths_helicopter))\n",
        "train_filenames_helicopter = image_paths_helicopter[:split_1]\n",
        "test_filenames_helicopter = image_paths_helicopter[split_2:]\n",
        "\n",
        "image_paths_train = train_filenames_car + train_filenames_deer + train_filenames_helicopter\n",
        "image_paths_test = test_filenames_car + test_filenames_deer + test_filenames_helicopter\n",
        "\n",
        "print(len(image_paths_train))\n",
        "print(len(image_paths_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrhkwQlkrF19"
      },
      "source": [
        "# Nuotraukų parsisiuntimas naudojantis downloadOI.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_qEUbGwQFYH"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BctmixpDVF1t"
      },
      "outputs": [],
      "source": [
        "# Download required meta-files\n",
        "!wget https://storage.googleapis.com/openimages/2018_04/class-descriptions-boxable.csv\n",
        " \n",
        "!wget https://storage.googleapis.com/openimages/2018_04/train/train-annotations-bbox.csv\n",
        " \n",
        "!wget https://storage.googleapis.com/openimages/2018_04/validation/validation-annotations-bbox.csv\n",
        " \n",
        "!wget https://storage.googleapis.com/openimages/2018_04/test/test-annotations-bbox.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPPlxckTVqbg"
      },
      "outputs": [],
      "source": [
        "!pip install awscli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32TfVRrh2JWN"
      },
      "outputs": [],
      "source": [
        "!python3 downloadOI.py --classes \"Deer,Car,Helicopter\" --mode train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5-1XTt3g2BH"
      },
      "outputs": [],
      "source": [
        "!python3 downloadOI.py --classes \"Deer,Car,Helicopter\" --mode test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avDY-MSsrNqg"
      },
      "source": [
        "# Nuotraukų kelių gavimas parsisiuntus naudojantis downloadOI.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsNsT0TJZC_P"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from pandas.core.common import flatten\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "from typing import Tuple, Dict, List\n",
        "\n",
        "import glob\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQaFQ-91Y-nQ"
      },
      "outputs": [],
      "source": [
        "def get_photo_paths(data_path):\n",
        "  image_paths = []\n",
        "  for data_path in glob.glob(data_path + '/*'):\n",
        "    paths = glob.glob(data_path + '/*')\n",
        "    print(data_path, ' ', len(paths))\n",
        "\n",
        "    for photo_path in paths:\n",
        "      if re.search(\".*jpg$\", photo_path):\n",
        "        image_paths.append(photo_path)\n",
        "    \n",
        "  return list(flatten(image_paths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PoH5X6Rm1Y2",
        "outputId": "c840b182-9d80-42a0-c343-22fde43ace89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/train/Deer   4186\n",
            "/content/train/Giraffe   1840\n",
            "/content/train/Elephant   3464\n",
            "/content/test/Deer   560\n",
            "/content/test/Giraffe   94\n",
            "/content/test/Elephant   272\n"
          ]
        }
      ],
      "source": [
        "image_classes = ['Deer', 'Car', 'Helicopter']\n",
        "data_dir = '/content'\n",
        "\n",
        "image_paths_train = get_photo_paths(data_dir + \"/train\")\n",
        "image_paths_test = get_photo_paths(data_dir + \"/test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEB7rs7orfdq"
      },
      "source": [
        "# Gpu/cpu device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6JFlIbKrZZb",
        "outputId": "b04b477e-caaf-46ca-efb6-57d9ba8fd634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zd7XGY1VsUHW"
      },
      "source": [
        "# Transformacijos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vrAlB1j1sRNh"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3UZNBqexrvvT"
      },
      "outputs": [],
      "source": [
        "transforms_test = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# transforms_train = transforms.Compose([\n",
        "#     transforms.Resize((128, 128)),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "# ])\n",
        "\n",
        "transforms_train = transforms.Compose([\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomGrayscale(),\n",
        "    transforms.ToTensor(),    \n",
        "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbZUHmkAroC6"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "S323KR7Ermpz"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1IOn9KxTrtnF"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "\n",
        "   def __init__(self, image_paths, transform=True):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "        \n",
        "   def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "   def __getitem__(self, idx):\n",
        "        image_filepath = self.image_paths[idx]\n",
        "        image = Image.open(image_filepath)\n",
        "        if image.mode is not 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "        image = self.transform(image)\n",
        "        \n",
        "        label = image_filepath.split('/')[1]  #[3]\n",
        "        label = class_to_idx[label]\n",
        "        \n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9hctB4WsvP7"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7lnMHammsw9m"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2lweJ8swsy0J"
      },
      "outputs": [],
      "source": [
        "num_workers = 2\n",
        "batch_size = 16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Itihx33ZxSu8"
      },
      "source": [
        "# Modelis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "HmBVJISSKOpZ"
      },
      "outputs": [],
      "source": [
        "class MyModel1(torch.nn.Module):\n",
        "  def __init__(self, in_shape, out_classes):\n",
        "    super().__init__()\n",
        "    self.num_classes = out_classes\n",
        "    \n",
        "    self.conv1_1 = torch.nn.Conv2d(in_shape[0], 32, (3, 3), padding = 'same')\n",
        "    self.conv1_2 = torch.nn.Conv2d(32, 32, (3, 3), padding = 'same')\n",
        "    self.conv2_1 = torch.nn.Conv2d(32, 64, (3, 3), padding = 'same')\n",
        "    self.conv2_2 = torch.nn.Conv2d(64, 64, (3, 3), padding = 'same')\n",
        "    self.fc1 = torch.nn.Linear(64 * (in_shape[1] // (2*2)) * (in_shape[2] // (2*2)), 224)\n",
        "    self.fc2 = torch.nn.Linear(224, 128)\n",
        "    self.fc3 = torch.nn.Linear(128, out_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y = torch.nn.Sequential(\n",
        "        self.conv1_1,\n",
        "        torch.nn.ReLU(),\n",
        "        self.conv1_2,\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d((2, 2), (2, 2)),\n",
        "\n",
        "        self.conv2_1,\n",
        "        torch.nn.ReLU(),\n",
        "        self.conv2_2,\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d((2, 2), (2, 2)),\n",
        "\n",
        "        torch.nn.Flatten(),\n",
        "        self.fc1,\n",
        "        torch.nn.ReLU(),\n",
        "        self.fc2,\n",
        "        torch.nn.ReLU(),\n",
        "        self.fc3\n",
        "    )(x)\n",
        "    return y\n",
        "\n",
        "# Epoch: 30, Time: 59m33s, Training loss: 0.12069132666344481\n",
        "# Training accuracy: 97.41, Validation accuracy: 89.03    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIXM6BhlPvON"
      },
      "outputs": [],
      "source": [
        "class MyModel2(torch.nn.Module):\n",
        "  def __init__(self, in_shape, out_classes):\n",
        "    super().__init__()\n",
        "    self.num_classes = out_classes\n",
        "    \n",
        "    self.conv1_1 = torch.nn.Conv2d(in_shape[0], 32, (3, 3), padding = 'same')\n",
        "    self.conv1_2 = torch.nn.Conv2d(32, 32, (3, 3), padding = 'same')\n",
        "    self.conv2_1 = torch.nn.Conv2d(32, 64, (3, 3), padding = 'same')\n",
        "    self.conv2_2 = torch.nn.Conv2d(64, 64, (3, 3), padding = 'same')\n",
        "    self.fc1 = torch.nn.Linear(64 * (in_shape[1] // (2*2)) * (in_shape[2] // (2*2)), 224)\n",
        "    self.fc2 = torch.nn.Linear(224, 224)\n",
        "    self.fc3 = torch.nn.Linear(224, out_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y = torch.nn.Sequential(\n",
        "        self.conv1_1,\n",
        "        torch.nn.ReLU(),\n",
        "        self.conv1_2,\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d((2, 2), (2, 2)),\n",
        "\n",
        "        self.conv2_1,\n",
        "        torch.nn.ReLU(),\n",
        "        self.conv2_2,\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d((2, 2), (2, 2)),\n",
        "\n",
        "        torch.nn.Flatten(),\n",
        "        self.fc1,\n",
        "        torch.nn.ReLU(),\n",
        "        self.fc2,\n",
        "        torch.nn.ReLU(),\n",
        "        self.fc3\n",
        "    )(x)\n",
        "    return y\n",
        "\n",
        "# Epoch: 20, Time: 41m42s, Training loss: 0.1866034850899816\n",
        "# Training accuracy: 93.44, Validation accuracy: 87.03    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "TC-rJ2H-5Auk"
      },
      "outputs": [],
      "source": [
        "class MyModel3(torch.nn.Module):\n",
        "  def __init__(self, in_shape, out_classes):\n",
        "    super().__init__()\n",
        "    self.num_classes = out_classes\n",
        "    \n",
        "    self.conv1_1 = torch.nn.Conv2d(in_shape[0], 64, (3, 3), padding = 'same')\n",
        "    self.conv1_2 = torch.nn.Conv2d(64, 64, (3, 3), padding = 'same')\n",
        "    self.conv2_1 = torch.nn.Conv2d(64, 128, (3, 3), padding = 'same')\n",
        "    self.fc1 = torch.nn.Linear(128 * (in_shape[1] // (2*2)) * (in_shape[2] // (2*2)), 516)\n",
        "    self.fc2 = torch.nn.Linear(516, 224)\n",
        "    self.fc3 = torch.nn.Linear(224, out_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y = torch.nn.Sequential(\n",
        "        self.conv1_1,\n",
        "        torch.nn.ReLU(),\n",
        "        self.conv1_2,\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d((2, 2), (2, 2)),\n",
        "\n",
        "        self.conv2_1,\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d((2, 2), (2, 2)),\n",
        "\n",
        "        torch.nn.Flatten(),\n",
        "        self.fc1,\n",
        "        torch.nn.ReLU(),\n",
        "        self.fc2,\n",
        "        torch.nn.ReLU(),\n",
        "        self.fc3\n",
        "    )(x)\n",
        "    return y\n",
        "\n",
        "# Epoch: 10, Time: 20m9s, Training loss: 0.1964600879411718\n",
        "# Training accuracy: 94.82, Validation accuracy: 85.79       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKg00-KQP6-4"
      },
      "outputs": [],
      "source": [
        "class MyModel4(torch.nn.Module):\n",
        "  def __init__(self, in_shape, out_classes):\n",
        "    super().__init__()\n",
        "    self.num_classes = out_classes\n",
        "    \n",
        "    self.conv1_1 = torch.nn.Conv2d(in_shape[0], 64, (7, 7), padding = 'same')\n",
        "    self.conv1_2 = torch.nn.Conv2d(64, 64, (3, 3), padding = 'same')\n",
        "    self.conv2_1 = torch.nn.Conv2d(64, 64, (3, 3), padding = 'same')\n",
        "    self.conv2_2 = torch.nn.Conv2d(64, 128, (3, 3), padding = 'same')\n",
        "    self.fc1 = torch.nn.Linear(128 * (in_shape[1] // (2*2)) * (in_shape[2] // (2*2)), 224)\n",
        "    self.fc2 = torch.nn.Linear(224, 128)\n",
        "    self.fc3 = torch.nn.Linear(128, out_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y = torch.nn.Sequential(\n",
        "        self.conv1_1,\n",
        "        torch.nn.ReLU(),\n",
        "        self.conv1_2,\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d((2, 2), (2, 2)),\n",
        "\n",
        "        self.conv2_1,\n",
        "        torch.nn.ReLU(),\n",
        "        self.conv2_2,\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d((2, 2), (2, 2)),\n",
        "\n",
        "        torch.nn.Flatten(),\n",
        "        self.fc1,\n",
        "        torch.nn.ReLU(),\n",
        "        self.fc2,\n",
        "        torch.nn.ReLU(),\n",
        "        self.fc3\n",
        "    )(x)\n",
        "    return y  \n",
        "\n",
        "# Epoch: 30, Time: 31m03s, Training loss: 0.14508988153127447\n",
        "# Training accuracy: 95.72, Validation accuracy: 83.54    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel5(torch.nn.Module):\n",
        "  def __init__(self, in_shape, out_classes):\n",
        "    super().__init__()\n",
        "    self.num_classes = out_classes\n",
        "    \n",
        "    self.conv1_1 = torch.nn.Conv2d(in_shape[0], 32, (3, 3), padding = 'same')\n",
        "    self.conv1_2 = torch.nn.Conv2d(32, 32, (3, 3), padding = 'same')\n",
        "    self.conv2_1 = torch.nn.Conv2d(32, 64, (3, 3), padding = 'same')\n",
        "    self.conv2_2 = torch.nn.Conv2d(64, 64, (3, 3), padding = 'same')\n",
        "    self.conv3_1 = torch.nn.Conv2d(64, 128, (3, 3), padding = 'same')\n",
        "    self.conv3_2 = torch.nn.Conv2d(128, 128, (3, 3), padding = 'same')\n",
        "    self.fc1 = torch.nn.Linear(128 * (in_shape[1] // (2*2*2)) * (in_shape[2] // (2*2*2)), 516)\n",
        "    self.fc2 = torch.nn.Linear(516, 224)\n",
        "    self.fc3 = torch.nn.Linear(224, out_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y = torch.nn.Sequential(\n",
        "        self.conv1_1,\n",
        "        torch.nn.ReLU(),\n",
        "        self.conv1_2,\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d((2, 2), (2, 2)),\n",
        "\n",
        "        self.conv2_1,\n",
        "        torch.nn.ReLU(),\n",
        "        self.conv2_2,\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d((2, 2), (2, 2)),\n",
        "\n",
        "        self.conv3_1,\n",
        "        torch.nn.ReLU(),\n",
        "        self.conv3_2,\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d((2, 2), (2, 2)),\n",
        "\n",
        "        torch.nn.Flatten(),\n",
        "        self.fc1,\n",
        "        torch.nn.ReLU(),\n",
        "        self.fc2,\n",
        "        torch.nn.ReLU(),\n",
        "        self.fc3\n",
        "    )(x)\n",
        "    return y\n",
        "\n",
        "# Epoch: 31, Time: 65m17s, Training loss: 0.10236165500639789\n",
        "# Training accuracy: 97.0, Validation accuracy: 86.53    "
      ],
      "metadata": {
        "id": "JlxHw26xzZ8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel6(torch.nn.Module):\n",
        "  def __init__(self, in_shape, out_classes):\n",
        "    super().__init__()\n",
        "    self.num_classes = out_classes\n",
        "    \n",
        "    self.conv1_1 = torch.nn.Conv2d(in_shape[0], 16, (3, 3), padding = 'same')\n",
        "    self.conv1_2 = torch.nn.Conv2d(16, 16, (3, 3), padding = 'same')\n",
        "    self.conv2_1 = torch.nn.Conv2d(16, 32, (3, 3), padding = 'same')\n",
        "    self.conv2_2 = torch.nn.Conv2d(32, 32, (3, 3), padding = 'same')\n",
        "    self.conv3_1 = torch.nn.Conv2d(32, 64, (3, 3), padding = 'same')\n",
        "    self.conv3_2 = torch.nn.Conv2d(64, 64, (3, 3), padding = 'same')\n",
        "    self.fc1 = torch.nn.Linear(64 * (in_shape[1] // (2*2*2)) * (in_shape[2] // (2*2*2)), 224)\n",
        "    self.fc2 = torch.nn.Linear(224, 128)\n",
        "    self.fc3 = torch.nn.Linear(128, out_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y = torch.nn.Sequential(\n",
        "        self.conv1_1,\n",
        "        torch.nn.ReLU(),\n",
        "        self.conv1_2,\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d((2, 2), (2, 2)),\n",
        "\n",
        "        self.conv2_1,\n",
        "        torch.nn.ReLU(),\n",
        "        self.conv2_2,\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d((2, 2), (2, 2)),\n",
        "\n",
        "        self.conv3_1,\n",
        "        torch.nn.ReLU(),\n",
        "        self.conv3_2,\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d((2, 2), (2, 2)),\n",
        "\n",
        "        torch.nn.Flatten(),\n",
        "        self.fc1,\n",
        "        torch.nn.ReLU(),\n",
        "        self.fc2,\n",
        "        torch.nn.ReLU(),\n",
        "        self.fc3\n",
        "    )(x)\n",
        "    return y\n",
        "\n",
        "# Epoch: 30, Time: 1h0m5s, Training loss: 0.1601044990224254\n",
        "# Training accuracy: 95.35, Validation accuracy: 85.79    "
      ],
      "metadata": {
        "id": "d4HPmk4NzcpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhU4qG86u9Ht"
      },
      "source": [
        "# Mokymo ir testavimo funkcijos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "rQIwZYRqw8Ra"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "k0FWb8DpK8_s"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, loader, loss_func, optimizer):\n",
        "  loss_acum = []\n",
        "  classes = model.num_classes\n",
        "\n",
        "  model.train()\n",
        "  \n",
        "  for data in loader:\n",
        "    images = data[0].to(device)\n",
        "    labels = torch.nn.functional.one_hot(data[1], classes).float().to(device)\n",
        "\n",
        "    pred = model(images)\n",
        "    loss = loss_func(pred, labels)\n",
        "    loss_acum = np.append(loss_acum, loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return np.mean(loss_acum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "mfn-eYbPPUEZ"
      },
      "outputs": [],
      "source": [
        "def train_all_epochs(model, loader, epoch_count = 15, lr = 1e-3):\n",
        "  loss_fn = torch.nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
        "\n",
        "  start_time = datetime.now()\n",
        "\n",
        "  train_accuracy_acum = []\n",
        "  valid_accuracy_acum = []\n",
        "\n",
        "  for epoch in range(epoch_count):\n",
        "    loss_avr = train_one_epoch(model, loader, loss_fn, optimizer)\n",
        "\n",
        "    # evaluation\n",
        "    train_accuracy = evaluate_while_training(model, loader_train)\n",
        "    train_accuracy_acum.append(train_accuracy)\n",
        "    valid_accuracy = evaluate_while_training(model, loader_test)\n",
        "    valid_accuracy_acum.append(valid_accuracy)\n",
        "\n",
        "    current_time = datetime.now()\n",
        "    elapsed = seconds_to_time((current_time - start_time).total_seconds())\n",
        "    print(f'Epoch: {epoch}, Time: {elapsed}, Training loss: {loss_avr}')\n",
        "    print(f'  Training accuracy: {np.round(train_accuracy * 100, 2)}, Validation accuracy: {np.round(valid_accuracy * 100, 2)}')\n",
        "\n",
        "  return train_accuracy_acum, valid_accuracy_acum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "suW0T9vYQPiz"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader):\n",
        "  model.eval()\n",
        "\n",
        "  ground_truth = []\n",
        "  predictions = []\n",
        "\n",
        "  for data in loader:\n",
        "    images = data[0].to(device)\n",
        "    labels = data[1]\n",
        "\n",
        "    with torch.no_grad():\n",
        "      output = model(images)\n",
        "      \n",
        "    pred_label = torch.argmax(output, axis = 1)\n",
        "    predictions = np.append(predictions, pred_label.cpu().detach())\n",
        "    ground_truth = np.append(ground_truth, labels)\n",
        "\n",
        "  return predictions, ground_truth "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "UROoMMOAmExu"
      },
      "outputs": [],
      "source": [
        "def evaluate_while_training(model, loader):\n",
        "  predictions, ground_truth = evaluate(model, loader)\n",
        "  correct_predictions = np.sum(predictions == ground_truth)\n",
        "  total_predictions = ground_truth.size\n",
        "  accuracy = correct_predictions / total_predictions\n",
        "  \n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FREhbEuySjAt"
      },
      "source": [
        "# Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "cnHYmBuFSm1h"
      },
      "outputs": [],
      "source": [
        "def create_confusion_matrix(predictions, ground_truth):\n",
        "  matrix = {}\n",
        "  matrix['00'] = np.sum(np.bitwise_and(ground_truth == 0, predictions == 0))\n",
        "  matrix['01'] = np.sum(np.bitwise_and(ground_truth == 0, predictions == 1))\n",
        "  matrix['02'] = np.sum(np.bitwise_and(ground_truth == 0, predictions == 2))\n",
        "  matrix['10'] = np.sum(np.bitwise_and(ground_truth == 1, predictions == 0))\n",
        "  matrix['11'] = np.sum(np.bitwise_and(ground_truth == 1, predictions == 1))\n",
        "  matrix['12'] = np.sum(np.bitwise_and(ground_truth == 1, predictions == 2))\n",
        "  matrix['20'] = np.sum(np.bitwise_and(ground_truth == 2, predictions == 0))\n",
        "  matrix['21'] = np.sum(np.bitwise_and(ground_truth == 2, predictions == 1))\n",
        "  matrix['22'] = np.sum(np.bitwise_and(ground_truth == 2, predictions == 2))\n",
        "\n",
        "  return matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhrM4aMRUB5L",
        "outputId": "27c3c3d5-3ed2-4098-8185-7d5117af7329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.9/dist-packages (0.8.10)\n"
          ]
        }
      ],
      "source": [
        "pip install tabulate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "SmKb7_bFVSFN"
      },
      "outputs": [],
      "source": [
        "from tabulate import tabulate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "CyBnCQRprTZI"
      },
      "outputs": [],
      "source": [
        "def print_class_matrix(matrix):\n",
        "\n",
        "  data = [['0', matrix['TN'], matrix['FP']], \n",
        "          ['1', matrix['FN'], matrix['TP']]]\n",
        "\n",
        "  print(tabulate(data, headers = ['True/Pred', '0', '1'], tablefmt = 'fancy_grid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "uAAnTEGfT5rm"
      },
      "outputs": [],
      "source": [
        "def print_confusion_matrix(matrix):\n",
        "  data = [['Deer', matrix['00'], matrix['01'], matrix['02']], \n",
        "         ['Car', matrix['10'], matrix['11'], matrix['12']], \n",
        "         ['Helicopter', matrix['20'], matrix['21'], matrix['22']]]\n",
        "\n",
        "  print(tabulate(data, headers = ['True/Pred', 'Deer', 'Car', 'Helicopter'], tablefmt = 'fancy_grid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTsIa-ajXvNG"
      },
      "source": [
        "# Metrikų skaičiavimas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "TVw_YJxDZEte"
      },
      "outputs": [],
      "source": [
        "def calculate_confusion_matrix_by_class(ground_truth, predictions, class_idx):\n",
        "  matrix = {}\n",
        "  matrix['TP'] = np.sum(np.bitwise_and(ground_truth == class_idx, predictions == class_idx))\n",
        "  matrix['TN'] = np.sum(np.bitwise_and(ground_truth == predictions, predictions != class_idx)) # groud true lygu prediction bet nelygu klasei\n",
        "  matrix['FP'] = np.sum(np.bitwise_and(ground_truth != class_idx, predictions == class_idx))\n",
        "  matrix['FN'] = np.sum(np.bitwise_and(ground_truth == class_idx, predictions != class_idx))\n",
        "\n",
        "  return matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "b8qbiQq5X6ed"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(matrix):\n",
        "  TP = matrix['TP']\n",
        "  TN = matrix['TN']\n",
        "  FP = matrix['FP']\n",
        "  FN = matrix['FN']\n",
        "\n",
        "  metrics = {}\n",
        "  metrics['accuracy'] = (TP + TN) / (TP + FP + TN + FN)\n",
        "  metrics['recall'] = TP / (TP + FN)\n",
        "  metrics['precision'] = TP / (TP + FP)\n",
        "  metrics['f1'] = 2 * (metrics['recall'] * metrics['precision']) / (metrics['recall'] + metrics['precision'])\n",
        "\n",
        "  return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1928Anp4R9Rt"
      },
      "source": [
        "# Veikimas ir skaičiavimai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "cFXNslsGsgAa"
      },
      "outputs": [],
      "source": [
        "dataset_train = MyDataset(image_paths_train, transforms_train)\n",
        "dataset_test = MyDataset(image_paths_test, transforms_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ue2eaWu_R-w6"
      },
      "outputs": [],
      "source": [
        "loader_train = DataLoader(dataset_train, batch_size = batch_size, shuffle=True, num_workers = num_workers)\n",
        "loader_test = DataLoader(dataset_test, batch_size = batch_size, shuffle=False, num_workers = num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "FitDUQBNKrB9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "8f3ed779-6c37-4954-d25c-bdc5620b2ce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter count: 67,862,727\n",
            "Epoch: 0, Time: 2m7s, Training loss: 0.7788318612089205\n",
            "  Training accuracy: 77.95, Validation accuracy: 76.56\n",
            "Epoch: 1, Time: 4m9s, Training loss: 0.5776749422301107\n",
            "  Training accuracy: 78.2, Validation accuracy: 80.8\n",
            "Epoch: 2, Time: 6m10s, Training loss: 0.5148737595152499\n",
            "  Training accuracy: 83.01, Validation accuracy: 80.8\n",
            "Epoch: 3, Time: 8m12s, Training loss: 0.4814926912146273\n",
            "  Training accuracy: 77.67, Validation accuracy: 82.29\n",
            "Epoch: 4, Time: 10m14s, Training loss: 0.4416010108086007\n",
            "  Training accuracy: 85.38, Validation accuracy: 84.54\n",
            "Epoch: 5, Time: 12m16s, Training loss: 0.42132431196410264\n",
            "  Training accuracy: 85.92, Validation accuracy: 84.04\n",
            "Epoch: 6, Time: 14m19s, Training loss: 0.40166354541717775\n",
            "  Training accuracy: 85.85, Validation accuracy: 82.54\n",
            "Epoch: 7, Time: 16m21s, Training loss: 0.3762625096671617\n",
            "  Training accuracy: 85.95, Validation accuracy: 78.05\n",
            "Epoch: 8, Time: 18m25s, Training loss: 0.3544962070140969\n",
            "  Training accuracy: 85.51, Validation accuracy: 77.56\n",
            "Epoch: 9, Time: 20m27s, Training loss: 0.33862113491145535\n",
            "  Training accuracy: 83.82, Validation accuracy: 80.55\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "model = MyModel3(dataset_train[0][0].shape, 3).to(device)\n",
        "print(f'Parameter count: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}')\n",
        "\n",
        "train_acc, valid_acc = train_all_epochs(model, loader_train, epoch_count = 10, lr = 1e-3)\n",
        "plot_accuracy(train_acc, valid_acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = MyModel1(dataset_train[0][0].shape, 3).to(device)\n",
        "print(f'Parameter count: {sum(p.numel() for p in model1.parameters() if p.requires_grad):,}')\n",
        "\n",
        "train_acc1, valid_acc1 = train_all_epochs(model1, loader_train, epoch_count = 30, lr = 1e-3)\n",
        "plot_accuracy(train_acc1, valid_acc1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yqtjDhOQM7wb",
        "outputId": "c339ad9e-e844-4d0b-b405-8733feba4544"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter count: 14,775,043\n",
            "Epoch: 0, Time: 2m3s, Training loss: 0.7351398890587821\n",
            "  Training accuracy: 77.83, Validation accuracy: 76.81\n",
            "Epoch: 1, Time: 4m4s, Training loss: 0.5817321541149225\n",
            "  Training accuracy: 75.39, Validation accuracy: 76.06\n",
            "Epoch: 2, Time: 6m6s, Training loss: 0.5135177257493954\n",
            "  Training accuracy: 83.35, Validation accuracy: 80.55\n",
            "Epoch: 3, Time: 8m8s, Training loss: 0.48958098284195906\n",
            "  Training accuracy: 83.26, Validation accuracy: 81.8\n",
            "Epoch: 4, Time: 10m10s, Training loss: 0.4547984316685603\n",
            "  Training accuracy: 85.23, Validation accuracy: 82.79\n",
            "Epoch: 5, Time: 12m12s, Training loss: 0.4342363477865262\n",
            "  Training accuracy: 83.67, Validation accuracy: 83.79\n",
            "Epoch: 6, Time: 14m14s, Training loss: 0.4265951639161774\n",
            "  Training accuracy: 83.07, Validation accuracy: 77.56\n",
            "Epoch: 7, Time: 16m17s, Training loss: 0.4190088932527535\n",
            "  Training accuracy: 87.54, Validation accuracy: 84.54\n",
            "Epoch: 8, Time: 18m20s, Training loss: 0.3862730506714897\n",
            "  Training accuracy: 85.88, Validation accuracy: 82.79\n",
            "Epoch: 9, Time: 20m22s, Training loss: 0.37329349889239266\n",
            "  Training accuracy: 88.13, Validation accuracy: 84.54\n",
            "Epoch: 10, Time: 22m24s, Training loss: 0.35634085969693624\n",
            "  Training accuracy: 88.54, Validation accuracy: 85.54\n",
            "Epoch: 11, Time: 24m25s, Training loss: 0.3108271957370476\n",
            "  Training accuracy: 87.73, Validation accuracy: 82.79\n",
            "Epoch: 12, Time: 26m27s, Training loss: 0.3066382531391744\n",
            "  Training accuracy: 87.85, Validation accuracy: 83.29\n",
            "Epoch: 13, Time: 28m27s, Training loss: 0.29422324339845285\n",
            "  Training accuracy: 90.19, Validation accuracy: 85.04\n",
            "Epoch: 14, Time: 30m29s, Training loss: 0.29027869327188427\n",
            "  Training accuracy: 90.38, Validation accuracy: 86.03\n",
            "Epoch: 15, Time: 32m29s, Training loss: 0.25822963676790694\n",
            "  Training accuracy: 91.29, Validation accuracy: 85.29\n",
            "Epoch: 16, Time: 34m31s, Training loss: 0.2564134865035465\n",
            "  Training accuracy: 90.47, Validation accuracy: 82.04\n",
            "Epoch: 17, Time: 36m33s, Training loss: 0.23490324217955866\n",
            "  Training accuracy: 92.1, Validation accuracy: 80.8\n",
            "Epoch: 18, Time: 38m36s, Training loss: 0.2095073518616643\n",
            "  Training accuracy: 94.28, Validation accuracy: 83.29\n",
            "Epoch: 19, Time: 40m37s, Training loss: 0.1916310003870607\n",
            "  Training accuracy: 91.97, Validation accuracy: 83.04\n",
            "Epoch: 20, Time: 42m39s, Training loss: 0.1956140368754642\n",
            "  Training accuracy: 94.07, Validation accuracy: 84.04\n",
            "Epoch: 21, Time: 44m42s, Training loss: 0.17180882399410602\n",
            "  Training accuracy: 95.88, Validation accuracy: 84.54\n",
            "Epoch: 22, Time: 46m44s, Training loss: 0.15986409674682797\n",
            "  Training accuracy: 95.07, Validation accuracy: 84.79\n",
            "Epoch: 23, Time: 48m48s, Training loss: 0.14752036196860804\n",
            "  Training accuracy: 95.0, Validation accuracy: 85.54\n",
            "Epoch: 24, Time: 50m51s, Training loss: 0.14778376674274937\n",
            "  Training accuracy: 96.63, Validation accuracy: 84.54\n",
            "Epoch: 25, Time: 52m54s, Training loss: 0.1263205302179564\n",
            "  Training accuracy: 95.47, Validation accuracy: 81.8\n",
            "Epoch: 26, Time: 54m57s, Training loss: 0.11731112151654595\n",
            "  Training accuracy: 96.19, Validation accuracy: 83.04\n",
            "Epoch: 27, Time: 57m2s, Training loss: 0.11411290312876485\n",
            "  Training accuracy: 92.22, Validation accuracy: 79.55\n",
            "Epoch: 28, Time: 59m3s, Training loss: 0.12386815978065874\n",
            "  Training accuracy: 97.1, Validation accuracy: 86.03\n",
            "Epoch: 29, Time: 1h1m7s, Training loss: 0.11033193116144055\n",
            "  Training accuracy: 97.6, Validation accuracy: 84.54\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "5Gf3JIEmSUES"
      },
      "outputs": [],
      "source": [
        "predictions, ground_truth = evaluate(model1, loader_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jowak-G7H-T0",
        "outputId": "d1a30dc1-dce8-4fe2-bd80-fddfb0eb939b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8453865336658354\n"
          ]
        }
      ],
      "source": [
        "correct_predictions = np.sum(predictions == ground_truth)\n",
        "total_predictions = ground_truth.size\n",
        "accuracy = correct_predictions / total_predictions\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "QJi6V5PrZq3U"
      },
      "outputs": [],
      "source": [
        "matrix_deer = calculate_confusion_matrix_by_class(ground_truth, predictions, class_to_idx['deer'])\n",
        "matrix_car = calculate_confusion_matrix_by_class(ground_truth, predictions, class_to_idx['car'])\n",
        "matrix_helicopter = calculate_confusion_matrix_by_class(ground_truth, predictions, class_to_idx['helicopter'])\n",
        "\n",
        "matrix_all = {}\n",
        "matrix_all['TP'] = matrix_deer['TP'] + matrix_car['TP'] + matrix_helicopter['TP']\n",
        "matrix_all['TN'] = matrix_deer['TN'] + matrix_car['TN'] + matrix_helicopter['TN']\n",
        "matrix_all['FP'] = matrix_deer['FP'] + matrix_car['FP'] + matrix_helicopter['FP']\n",
        "matrix_all['FN'] = matrix_deer['FN'] + matrix_car['FN'] + matrix_helicopter['FN']\n",
        "\n",
        "metrics_deer = calculate_metrics(matrix_deer)\n",
        "metrics_car = calculate_metrics(matrix_car)\n",
        "metrics_helicopter = calculate_metrics(matrix_helicopter)\n",
        "metrics_all = calculate_metrics(matrix_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCcoW4zaXVCz",
        "outputId": "120c585b-fdca-4c8a-d5fd-a8cd2ffb55e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╒═════════════╤════════╤═══════╤══════════════╕\n",
            "│ True/Pred   │   Deer │   Car │   Helicopter │\n",
            "╞═════════════╪════════╪═══════╪══════════════╡\n",
            "│ Deer        │     76 │    11 │            7 │\n",
            "├─────────────┼────────┼───────┼──────────────┤\n",
            "│ Car         │      3 │   184 │           13 │\n",
            "├─────────────┼────────┼───────┼──────────────┤\n",
            "│ Helicopter  │      6 │    22 │           79 │\n",
            "╘═════════════╧════════╧═══════╧══════════════╛\n"
          ]
        }
      ],
      "source": [
        "matrix = create_confusion_matrix(predictions, ground_truth)\n",
        "print_confusion_matrix(matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5D29X0-skrG",
        "outputId": "08f2476d-f559-4f6f-822b-31c26b5a725b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deer matrix\n",
            "╒═════════════╤═════╤═════╕\n",
            "│   True/Pred │   0 │   1 │\n",
            "╞═════════════╪═════╪═════╡\n",
            "│           0 │ 263 │   9 │\n",
            "├─────────────┼─────┼─────┤\n",
            "│           1 │  18 │  76 │\n",
            "╘═════════════╧═════╧═════╛\n",
            "Car matrix\n",
            "╒═════════════╤═════╤═════╕\n",
            "│   True/Pred │   0 │   1 │\n",
            "╞═════════════╪═════╪═════╡\n",
            "│           0 │ 155 │  33 │\n",
            "├─────────────┼─────┼─────┤\n",
            "│           1 │  16 │ 184 │\n",
            "╘═════════════╧═════╧═════╛\n",
            "Helicopter matrix\n",
            "╒═════════════╤═════╤═════╕\n",
            "│   True/Pred │   0 │   1 │\n",
            "╞═════════════╪═════╪═════╡\n",
            "│           0 │ 260 │  20 │\n",
            "├─────────────┼─────┼─────┤\n",
            "│           1 │  28 │  79 │\n",
            "╘═════════════╧═════╧═════╛\n",
            "All matrix\n",
            "╒═════════════╤═════╤═════╕\n",
            "│   True/Pred │   0 │   1 │\n",
            "╞═════════════╪═════╪═════╡\n",
            "│           0 │ 678 │  62 │\n",
            "├─────────────┼─────┼─────┤\n",
            "│           1 │  62 │ 339 │\n",
            "╘═════════════╧═════╧═════╛\n"
          ]
        }
      ],
      "source": [
        "print('Deer matrix')\n",
        "print_class_matrix(matrix_deer)\n",
        "print('Car matrix')\n",
        "print_class_matrix(matrix_car)\n",
        "print('Helicopter matrix')\n",
        "print_class_matrix(matrix_helicopter)\n",
        "print('All matrix')\n",
        "print_class_matrix(matrix_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RSPvXALuGjk",
        "outputId": "0323543f-506c-4a40-b096-274e2e09e8a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class  deer  metrics:\n",
            "  accuracy :  0.9262295081967213\n",
            "  recall :  0.8085106382978723\n",
            "  precision :  0.8941176470588236\n",
            "  f1 :  0.8491620111731844\n",
            "\n",
            "Class  car  metrics:\n",
            "  accuracy :  0.8737113402061856\n",
            "  recall :  0.92\n",
            "  precision :  0.847926267281106\n",
            "  f1 :  0.882494004796163\n",
            "\n",
            "Class  helicopter  metrics:\n",
            "  accuracy :  0.875968992248062\n",
            "  recall :  0.7383177570093458\n",
            "  precision :  0.797979797979798\n",
            "  f1 :  0.766990291262136\n",
            "\n",
            "All   metrics:\n",
            "  accuracy :  0.8913234005258545\n",
            "  recall :  0.8453865336658354\n",
            "  precision :  0.8453865336658354\n",
            "  f1 :  0.8453865336658354\n"
          ]
        }
      ],
      "source": [
        "print_metrics(metrics_deer, class_to_idx['deer'])\n",
        "print_metrics(metrics_car, class_to_idx['car'])\n",
        "print_metrics(metrics_helicopter, class_to_idx['helicopter'])\n",
        "print_all_metrics(metrics_all)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_image_label(model, 'https://media.npr.org/assets/img/2021/11/10/white-tailed-deer-1-ac07593f0b38e66ffac9178fb0c787ca75baea3d.jpg'))"
      ],
      "metadata": {
        "id": "o7dDz-Yh46n4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b36e6bd-3cb4-4f22-f3ef-d5620868242b"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0ON-TCIw-f_"
      },
      "source": [
        "# Papildomos funkcijos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_label(model, url):\n",
        "  model.eval()\n",
        "  image = Image.open(requests.get(url, stream=True).raw)\n",
        "  # response = requests.get(url)\n",
        "  # image = Image.open(BytesIO(response.content))\n",
        "  image = transforms_test(image)\n",
        "  output = model(image.unsqueeze(0).to(device))\n",
        "  pred_label = torch.argmax(output, axis = 1)\n",
        "\n",
        "  return idx_to_class[pred_label.item()]"
      ],
      "metadata": {
        "id": "7Rwrz0QY42oS"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b5pgF61rzDQ",
        "outputId": "c096e3fa-ce19-4d78-cdae-681e6f032e12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'deer', 1: 'car', 2: 'helicopter'}\n",
            "{'deer': 0, 'car': 1, 'helicopter': 2}\n"
          ]
        }
      ],
      "source": [
        "# Pagalbinės funkcijos verčiant pavadinimą (label) į indeksą\n",
        "idx_to_class = {i:j for i, j in enumerate(image_classes)}\n",
        "class_to_idx = {value:key for key, value in idx_to_class.items()}\n",
        "print(idx_to_class)\n",
        "print(class_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "haHoqKqqR-tx"
      },
      "outputs": [],
      "source": [
        "def seconds_to_time(seconds):\n",
        "    s = int(seconds) % 60\n",
        "    m = int(seconds) // 60\n",
        "    if m < 1:\n",
        "        return f'{s}s'\n",
        "    h = m // 60\n",
        "    m = m % 60\n",
        "    if h < 1:\n",
        "        return f'{m}m{s}s'\n",
        "    return f'{h}h{m}m{s}s'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ixbalswClhcD"
      },
      "outputs": [],
      "source": [
        "def plot_accuracy(train_accuracy, valid_accuracy):\n",
        "  plt.clf()\n",
        "  plt.plot(train_accuracy, 'b', label = 'Training accuracy')\n",
        "  plt.plot(valid_accuracy, 'r', label = 'Validation accuracy')\n",
        "  plt.ylim(0.0, 1.0)\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0EHcVvX9t-j3"
      },
      "outputs": [],
      "source": [
        "def print_metrics(metrics, class_idx):\n",
        "  print('Class ', idx_to_class[class_idx], ' metrics:')\n",
        "  print('  accuracy : ', metrics['accuracy'])\n",
        "  print('  recall : ', metrics['recall'])\n",
        "  print('  precision : ', metrics['precision'])\n",
        "  print('  f1 : ', metrics['f1'])\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Wnr41SEuuCEg"
      },
      "outputs": [],
      "source": [
        "def print_all_metrics(metrics):\n",
        "  print('All ', ' metrics:')\n",
        "  print('  accuracy : ', metrics['accuracy'])\n",
        "  print('  recall : ', metrics['recall'])\n",
        "  print('  precision : ', metrics['precision'])\n",
        "  print('  f1 : ', metrics['f1'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "qgrUeICX7NXI",
        "qrhkwQlkrF19",
        "avDY-MSsrNqg",
        "IEB7rs7orfdq",
        "Zd7XGY1VsUHW",
        "DbZUHmkAroC6",
        "F9hctB4WsvP7",
        "Itihx33ZxSu8",
        "AhU4qG86u9Ht",
        "FREhbEuySjAt",
        "LTsIa-ajXvNG",
        "1928Anp4R9Rt",
        "U0ON-TCIw-f_"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}